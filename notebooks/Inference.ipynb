{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f996d531-60dc-4ba0-b14f-6c910b9ec862",
   "metadata": {},
   "source": [
    "# 3. Inference of trained model for forest classification\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc58ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio \n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import dump, load\n",
    "import enum \n",
    "import datetime as dt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from scipy.stats import entropy\n",
    "from itertools import product\n",
    "from rasterio import windows\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485835e4-6f86-4350-8015-3ff7ecd97cd6",
   "metadata": {},
   "source": [
    "## 3.1 Utils to compute spectral indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1748d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDVI(red: pd.Series, nir: pd.Series):\n",
    "    ndvi = (nir - red) / ((nir + red).apply(lambda x: 0.000001 if x == 0 else x))\n",
    "    return ndvi\n",
    "\n",
    "def EVI(red: pd.Series, nir: pd.Series):\n",
    "    evi2 = (\n",
    "        2.5\n",
    "        * (nir - red)\n",
    "        / ((nir + 2.4 * red + 1).apply(lambda x: 0.000001 if x == 0 else x))\n",
    "    )\n",
    "    return evi2\n",
    "\n",
    "def NDRE(red_far: pd.Series, nir: pd.Series):\n",
    "    ndre = (nir - red_far) / (\n",
    "        (nir + red_far).apply(lambda x: 0.000001 if x == 0 else x)\n",
    "    )\n",
    "    return ndre\n",
    "\n",
    "def MSAVI(red: pd.Series, nir: pd.Series):\n",
    "    msavi = (2 * nir + 1 - ((2 * nir + 1) ** 2 - 8 * (nir - red)) ** (1 / 2)) / 2\n",
    "    return msavi\n",
    "\n",
    "\n",
    "def FCI(red: pd.Series, nir: pd.Series):\n",
    "    fci = np.sqrt(red * nir)\n",
    "    return fci\n",
    "\n",
    "def normalize_pixel(X: np.ndarray) -> np.ndarray:\n",
    "        X = X / 10000\n",
    "        X = np.clip(X, 0, 0.3)\n",
    "        return X\n",
    "    \n",
    "        \n",
    "def get_SVI(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    nir = df.loc[:, \"B08\"]\n",
    "    red = df.loc[:, \"B04\"]\n",
    "    red_far = df.loc[:, \"B05\"]\n",
    "    df.loc[:, \"NDVI\"] = NDVI(red=red, nir=nir)\n",
    "    df.loc[:, \"NDRE\"] = NDRE(red_far=red_far, nir=nir)\n",
    "    df.loc[:, \"MSAVI\"] = MSAVI(red=red, nir=nir)\n",
    "    df.loc[:, \"EVI\"] = EVI(red=red, nir=nir)\n",
    "    df.loc[:, \"FCI\"] = FCI(red=red, nir=nir)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_tiles(ds, width=256, height=256):\n",
    "    nols, nrows = ds.meta['width'], ds.meta['height']\n",
    "    offsets = product(range(0, nols, width), range(0, nrows, height))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    for col_off, row_off in  offsets:\n",
    "        window =windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ds.transform)\n",
    "        yield window, transform\n",
    "\n",
    "def get_dataset(x: np.ndarray)->pd.DataFrame:\n",
    "    col_names = [\"B01\",\"B02\",\"B03\",\"B04\",\n",
    "            \"B05\",\"B06\",\"B07\",\"B08\",\n",
    "            \"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"]\n",
    "    bands = to_2d_array(x[:13, ...])    \n",
    "    df = pd.DataFrame(bands.T, columns=col_names)\n",
    "    df[col_names] = normalize_pixel(df.values)\n",
    "    df = df.drop(columns='B10')\n",
    "    df = get_SVI(df)\n",
    "    terrain = to_2d_array(x[16:20, ...])\n",
    "    df_terrain = pd.DataFrame(terrain.T, columns=[\"aspect\", \"slope\", \n",
    "                                                      \"wetnessindex\", \"sink\"])\n",
    "    mask = df_terrain['wetnessindex']<0\n",
    "    df_terrain.loc[mask,'wetnessindex']=0\n",
    "    texture = to_2d_array(x[20:32, ...])\n",
    "    texture_columns = [\"ASM1\",\"ASM2\",\n",
    "                        \"contrast1\",\"contrast2\",\n",
    "                        \"correlation1\",\"correlation2\",\n",
    "                        \"dissimilarity1\",\"dissimilarity2\",\n",
    "                        \"energy1\",\"energy2\",\n",
    "                        \"homogeneity1\",\"homogeneity2\"]\n",
    "\n",
    "    df_texture = pd.DataFrame(texture.T, columns=texture_columns)\n",
    "    forest_mask = to_2d_array(x[-1:, ...])\n",
    "    df_forest = pd.DataFrame(forest_mask.T, columns=['forest_mask'])\n",
    "    return pd.concat([df,df_terrain, df_texture, df_forest], axis=1)\n",
    "\n",
    "def to_2d_array(x: np.ndarray)->np.ndarray:\n",
    "    return x.reshape(x.shape[0], x.shape[1] * x.shape[2])\n",
    "\n",
    "def save_tif_rasterio(\n",
    "        raster_input: str, raster_output: str, values: np.ndarray, dtypes: rio.float32,  nodata: int = 0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save numpy array to geotiff\n",
    "        \"\"\"\n",
    "        with rio.open(raster_input, \"r+\") as src:\n",
    "            kwargs = src.meta\n",
    "            kwargs.update(dtype=dtypes, count=1, compress=\"lzw\", nodata=nodata)\n",
    "        with rio.open(raster_output, \"w\", **kwargs) as dst:\n",
    "            dst.write_band(1, values.astype(dtypes))\n",
    "            print(f\"Saved geotiff: {raster_output}\")\n",
    "\n",
    "def get_scaled_data(path:str, cols_remove:list=['key', 'class']):\n",
    "    df = pd.read_csv(path)\n",
    "    mask = df['class']!=2\n",
    "    df=df.loc[mask]\n",
    "    x = df.drop(columns=cols_remove).values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler() \n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    target_cols = [col for col in list(df.columns) if col not in cols_remove]\n",
    "    df.loc[:, target_cols] = x_scaled\n",
    "    return df, min_max_scaler\n",
    "\n",
    "def get_calibrated(df:pd.DataFrame, model):\n",
    "    clf = CalibratedClassifierCV(model) \n",
    "    df = df.sample(int(len(df)*0.7))\n",
    "    y_train = df['class']\n",
    "    x_train = df.drop(columns=['key', 'class'])\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1f663-2a39-436e-8839-b1c93496a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd99e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e785d407504545f78d839d2bd49a906c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved geotiff: ../rasters/prediction_SVM_UQ.tif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f105c25f9bf6400dbcec8d60a396733e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved geotiff: ../rasters/prediction_RF_UQ.tif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc5ae6dbf784bcdb4f00027c7db7e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved geotiff: ../rasters/prediction_kNN_UQ.tif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0234ee1a9a472fa3762df0eb89ef75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved geotiff: ../rasters/prediction_XGB_UQ.tif\n"
     ]
    }
   ],
   "source": [
    "# Size ot tiles for classification\n",
    "tile_width, tile_height = 512, 512\n",
    "\n",
    "models = {'kNN':{'model': '../models/best_models/kNN_df1_filtered_modified.joblib',\n",
    "                 'input_file': 'df1_filtered_modified.csv'},\n",
    "          'XGB':{'model': '../models/best_models/XGB_df2_filtered_modified.joblib',\n",
    "                 'input_file': 'df2_filtered_modified.csv'},\n",
    "          'SVM':{'model': '../models/best_models/SVC_df5_filtered_modified.joblib',\n",
    "                 'input_file': 'df5_filtered_modified.csv'},\n",
    "          'RF':{'model': '../models/best_models/RandomForest_df3_filtered_modified.joblib',\n",
    "                 'input_file': 'df3_filtered_modified.csv'}}\n",
    "\n",
    "\n",
    "fname = '../rasters/dataset.tiff'\n",
    "folder = '../shape_data/filtered_datasets_2024/'\n",
    "\n",
    "for model in ['SVM', 'RF', 'kNN', 'XGB']:\n",
    "    model_fname = models[model]['model']\n",
    "    forest_model = load(model_fname)\n",
    "    df_scaled, min_max_scaler = get_scaled_data(os.path.join(folder, models[model]['input_file']))\n",
    "    df_forest = df_scaled.loc[df_scaled['class']<10]\n",
    "    if model=='SVM':\n",
    "        forest_model = get_calibrated(df=df_forest, model=forest_model)\n",
    "    le = LabelEncoder()\n",
    "    le.fit_transform(df_forest['class'])\n",
    "\n",
    "    n = 0\n",
    "    with rio.open(fname, 'r') as src:\n",
    "        meta = src.meta.copy()\n",
    "        output_mask = np.zeros(shape = (meta['height'], meta['width']))\n",
    "        output_mask_proba = np.zeros(shape = (meta['height'], meta['width']))\n",
    "        # Здесь можно добавить tqdm для отслеживания процесса\n",
    "            \n",
    "        for window, transform in tqdm(get_tiles(src, \n",
    "                                           width=tile_width,\n",
    "                                           height=tile_height)):\n",
    "            meta['transform'] = transform\n",
    "            meta['width'], meta['height'] = window.width, window.height\n",
    "            \n",
    "            x = src.read(window=window)\n",
    "            # get pixels for classification from tiff tile\n",
    "            df = get_dataset(x)\n",
    "            # vector to save results\n",
    "            forecast=pd.Series(data=np.ones(shape=(len(df), 1)[0])*-999)\n",
    "        \n",
    "            mask_nan = df.iloc[:, :13].sum(axis=1)==0\n",
    "            land_df = df.loc[~mask_nan]\n",
    "            if len(land_df)!=0:\n",
    "                land_df.iloc[:, :-1] = min_max_scaler.transform(land_df.iloc[:, :-1])\n",
    "                \n",
    "                forecast_mask = (land_df['forest_mask']==2)\n",
    "                forecast.loc[~mask_nan] = (forecast_mask*1).values\n",
    "                forecast.loc[forecast<1]=-999\n",
    "                mask_forest = forecast==1\n",
    "                land_df = land_df.drop(columns='forest_mask')\n",
    "                forecast_probability = forecast.copy()\n",
    "                if model=='XGB':\n",
    "                    le = LabelEncoder()\n",
    "                    le.fit_transform(df_forest['class'])\n",
    "                    predictors_raw = forest_model.predict(land_df[forest_model.feature_names_in_].loc[mask_forest])\n",
    "                    predictors = le.inverse_transform(predictors_raw)\n",
    "                    forecast.loc[mask_forest] = predictors\n",
    "                else:\n",
    "                    forecast.loc[mask_forest] = forest_model.predict(land_df[forest_model.feature_names_in_].loc[mask_forest])\n",
    "                # if model=='SVM':\n",
    "                    # prob_predictions = np.max(forest_model.predict_proba(land_df[forest_model.feature_names_in_].loc[mask_forest]),\n",
    "                    #                                                axis=1)\n",
    "                probabilities = forest_model.predict_proba(land_df[forest_model.feature_names_in_].loc[mask_forest])\n",
    "                # print(np.min(probabilities), np.max(probabilities))\n",
    "                entropy_predictions = entropy(probabilities,axis=1)\n",
    "                entropy_predictions = np.round(entropy_predictions, 3)\n",
    "                # print(np.min(entropy_predictions), np.max(entropy_predictions))\n",
    "                forecast_probability.loc[mask_forest] = entropy_predictions\n",
    "                # else:\n",
    "                #     # forecast_probability.loc[mask_forest] = np.max(forest_model.predict_proba(land_df[forest_model.feature_names_in_].loc[mask_forest]),\n",
    "                #     #                                                axis=1)\n",
    "                #     forecast_probability.loc[mask_forest] = entropy(forest_model.predict_proba(land_df[forest_model.feature_names_in_].loc[mask_forest]),\n",
    "                #                                                    axis=1)\n",
    "                    \n",
    "            else:\n",
    "                forecast_probability = forecast.copy()\n",
    "            forest_tile = forecast.values.reshape(meta['height'], meta['width'])\n",
    "            # forest_tile[forest_tile<0]=0\n",
    "            ranges = window.toranges()\n",
    "            output_mask[ranges[0][0]:ranges[0][1],ranges[1][0]:ranges[1][1]] = forest_tile\n",
    "            # forecast_probability[forecast_probability<=0] = -1.\n",
    "            forest_tile_proba = forecast_probability.values.reshape(meta['height'], meta['width'])\n",
    "            output_mask_proba[ranges[0][0]:ranges[0][1],ranges[1][0]:ranges[1][1]] = forest_tile_proba\n",
    "            n = n+1\n",
    "            # if n==5:\n",
    "            #     break\n",
    "    # raster_input = fname\n",
    "    # raster_output = f'../rasters/prediction_{model}.tif'\n",
    "    # save_tif_rasterio(raster_input=raster_input, raster_output=raster_output, values=output_mask,  dtypes=rio.int16, nodata=0)\n",
    "    \n",
    "    raster_input = fname\n",
    "    raster_output = f'../rasters/prediction_{model}_UQ.tif'\n",
    "    save_tif_rasterio(raster_input=raster_input, raster_output=raster_output, values=output_mask_proba, dtypes=rio.float32,  \n",
    "                      nodata=np.min(forest_tile_proba))\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
